{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gender_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c5857649ae04bbfa7d30db8e06d2cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2cc2ccbe02fc4f9a8ae075844b83aa5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f49f5aa955f4123b8a9bac89bfa66e0",
              "IPY_MODEL_4fd9af537ee74951b1f4865d7223dc8d"
            ]
          }
        },
        "2cc2ccbe02fc4f9a8ae075844b83aa5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f49f5aa955f4123b8a9bac89bfa66e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a925ea5cdfb45aca0ff88a53142b963",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccd775116599487caec2b41ca332380f"
          }
        },
        "4fd9af537ee74951b1f4865d7223dc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_465031725f134786bdbbe27b0db70665",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [28:06&lt;00:00, 1686.34s/epoch]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f80a928706746cb9c109a157796fa45"
          }
        },
        "9a925ea5cdfb45aca0ff88a53142b963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccd775116599487caec2b41ca332380f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "465031725f134786bdbbe27b0db70665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f80a928706746cb9c109a157796fa45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b594fbd1810b4b159b457704732b4a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2693dc386d014fb08cc41f5a5676fa7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54eb6dc89e9e4412857ac1a1f3ad92cb",
              "IPY_MODEL_79d01993f70046a0a18019632aa9a3b9"
            ]
          }
        },
        "2693dc386d014fb08cc41f5a5676fa7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54eb6dc89e9e4412857ac1a1f3ad92cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6aa2f31ee9734303be828c562b279a99",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1e335d31f4640f79dbd6ea5c32788cc"
          }
        },
        "79d01993f70046a0a18019632aa9a3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64a65d46d01349ba8997915ee76f8de5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [1:08:46&lt;00:00, 41.26s/epoch]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3930ec55c0464582ac367faf1d76c693"
          }
        },
        "6aa2f31ee9734303be828c562b279a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1e335d31f4640f79dbd6ea5c32788cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64a65d46d01349ba8997915ee76f8de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3930ec55c0464582ac367faf1d76c693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FawNm3wX00E"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os,glob\n",
        "from tqdm import tqdm_notebook\n",
        "import re\n",
        "import random\n",
        "from random import randint\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaon91u5dCDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b616ef2-3d15-4a58-e4da-6779eaa6f04b"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=5205019b05eb6e1c034f25357ef3661685d22926a47d401269883144eb022863\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPTlRgqSdVRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaae4d24-ea87-44c7-bda2-b0e16b89ade0"
      },
      "source": [
        "cd \"/content/drive/My Drive/gender_detection/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gender_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNv8t8RfXrhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c5857649ae04bbfa7d30db8e06d2cb0",
            "2cc2ccbe02fc4f9a8ae075844b83aa5c",
            "3f49f5aa955f4123b8a9bac89bfa66e0",
            "4fd9af537ee74951b1f4865d7223dc8d",
            "9a925ea5cdfb45aca0ff88a53142b963",
            "ccd775116599487caec2b41ca332380f",
            "465031725f134786bdbbe27b0db70665",
            "7f80a928706746cb9c109a157796fa45"
          ]
        },
        "outputId": "326e4f30-1b9b-4c67-cf12-95f61c912621"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4.dammit import EncodingDetector\n",
        "import requests\n",
        "count=0\n",
        "#79,80\n",
        "for i in tqdm_notebook(range(83,84), total=1, unit=\"epoch\"):\n",
        "  print(i)\n",
        "  parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
        "  resp = requests.get(\"https://www.openslr.org/\"+str(i)+\"/\")\n",
        "  http_encoding = resp.encoding if 'charset' in resp.headers.get('content-type', '').lower() else None\n",
        "  html_encoding = EncodingDetector.find_declared_encoding(resp.content, is_html=True)\n",
        "  encoding = html_encoding or http_encoding\n",
        "  soup = BeautifulSoup(resp.content, parser, from_encoding=encoding)\n",
        "  \n",
        "  for link in soup.find_all('a', href=True):\n",
        "    l=link[\"href\"].split(\".\")\n",
        "    if l[len(l)-1]==\"zip\" or l[len(l)-1]==\"tgz\":\n",
        "      if l[1]==\"openslr\":\n",
        "        count=count+1\n",
        "        name=l[len(l)-2].split(\"/\")\n",
        "        #print(link[\"href\"],l[1],name[len(name)-1])\n",
        "        file_url = link[\"href\"]\n",
        "        #print(file_url)\n",
        "        !wget -c $file_url\n",
        "        # r = requests.get(file_url, stream = True)  \n",
        "          \n",
        "        # with open(\"/content/drive/My Drive/gender_detection/\"+name[len(name)-1]+\".\"+l[len(l)-1], \"wb\") as file:  \n",
        "        #     for block in r.iter_content(chunk_size = 1024): \n",
        "        #         if block:  \n",
        "        #             file.write(block)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c5857649ae04bbfa7d30db8e06d2cb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "83\n",
            "--2020-10-31 14:30:49--  http://www.openslr.org/resources/83/irish_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164531638 (157M) [application/zip]\n",
            "Saving to: â€˜irish_english_male.zipâ€™\n",
            "\n",
            "irish_english_male. 100%[===================>] 156.91M  18.2MB/s    in 9.2s    \n",
            "\n",
            "2020-10-31 14:30:59 (17.1 MB/s) - â€˜irish_english_male.zipâ€™ saved [164531638/164531638]\n",
            "\n",
            "--2020-10-31 14:30:59--  http://www.openslr.org/resources/83/midlands_english_female.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103085118 (98M) [application/zip]\n",
            "Saving to: â€˜midlands_english_female.zipâ€™\n",
            "\n",
            "midlands_english_fe 100%[===================>]  98.31M  19.6MB/s    in 6.2s    \n",
            "\n",
            "2020-10-31 14:31:05 (15.9 MB/s) - â€˜midlands_english_female.zipâ€™ saved [103085118/103085118]\n",
            "\n",
            "--2020-10-31 14:31:05--  http://www.openslr.org/resources/83/midlands_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166833961 (159M) [application/zip]\n",
            "Saving to: â€˜midlands_english_male.zipâ€™\n",
            "\n",
            "midlands_english_ma 100%[===================>] 159.10M  19.1MB/s    in 12s     \n",
            "\n",
            "2020-10-31 14:31:18 (12.8 MB/s) - â€˜midlands_english_male.zipâ€™ saved [166833961/166833961]\n",
            "\n",
            "--2020-10-31 14:31:18--  http://www.openslr.org/resources/83/northern_english_female.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314983063 (300M) [application/zip]\n",
            "Saving to: â€˜northern_english_female.zipâ€™\n",
            "\n",
            "northern_english_fe 100%[===================>] 300.39M  17.3MB/s    in 17s     \n",
            "\n",
            "2020-10-31 14:31:36 (17.8 MB/s) - â€˜northern_english_female.zipâ€™ saved [314983063/314983063]\n",
            "\n",
            "--2020-10-31 14:31:36--  http://www.openslr.org/resources/83/northern_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 817772034 (780M) [application/zip]\n",
            "Saving to: â€˜northern_english_male.zipâ€™\n",
            "\n",
            "northern_english_ma 100%[===================>] 779.89M  15.4MB/s    in 43s     \n",
            "\n",
            "2020-10-31 14:32:19 (18.1 MB/s) - â€˜northern_english_male.zipâ€™ saved [817772034/817772034]\n",
            "\n",
            "--2020-10-31 14:32:19--  http://www.openslr.org/resources/83/scottish_english_female.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 351443880 (335M) [application/zip]\n",
            "Saving to: â€˜scottish_english_female.zipâ€™\n",
            "\n",
            "scottish_english_fe 100%[===================>] 335.16M  19.8MB/s    in 20s     \n",
            "\n",
            "2020-10-31 14:32:39 (16.7 MB/s) - â€˜scottish_english_female.zipâ€™ saved [351443880/351443880]\n",
            "\n",
            "--2020-10-31 14:32:39--  http://www.openslr.org/resources/83/scottish_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 620254118 (592M) [application/zip]\n",
            "Saving to: â€˜scottish_english_male.zipâ€™\n",
            "\n",
            "scottish_english_ma 100%[===================>] 591.52M  20.2MB/s    in 32s     \n",
            "\n",
            "2020-10-31 14:33:12 (18.2 MB/s) - â€˜scottish_english_male.zipâ€™ saved [620254118/620254118]\n",
            "\n",
            "--2020-10-31 14:33:12--  http://www.openslr.org/resources/83/southern_english_female.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1636701939 (1.5G) [application/zip]\n",
            "Saving to: â€˜southern_english_female.zipâ€™\n",
            "\n",
            "southern_english_fe 100%[===================>]   1.52G  20.6MB/s    in 82s     \n",
            "\n",
            "2020-10-31 14:34:35 (18.9 MB/s) - â€˜southern_english_female.zipâ€™ saved [1636701939/1636701939]\n",
            "\n",
            "--2020-10-31 14:34:35--  http://www.openslr.org/resources/83/southern_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1700955740 (1.6G) [application/zip]\n",
            "Saving to: â€˜southern_english_male.zipâ€™\n",
            "\n",
            "southern_english_ma 100%[===================>]   1.58G  19.4MB/s    in 86s     \n",
            "\n",
            "2020-10-31 14:36:01 (18.8 MB/s) - â€˜southern_english_male.zipâ€™ saved [1700955740/1700955740]\n",
            "\n",
            "--2020-10-31 14:36:02--  http://www.openslr.org/resources/83/welsh_english_female.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 595683538 (568M) [application/zip]\n",
            "Saving to: â€˜welsh_english_female.zipâ€™\n",
            "\n",
            "welsh_english_femal 100%[===================>] 568.09M  19.3MB/s    in 31s     \n",
            "\n",
            "2020-10-31 14:36:34 (18.1 MB/s) - â€˜welsh_english_female.zipâ€™ saved [595683538/595683538]\n",
            "\n",
            "--2020-10-31 14:36:34--  http://www.openslr.org/resources/83/welsh_english_male.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 757645790 (723M) [application/zip]\n",
            "Saving to: â€˜welsh_english_male.zipâ€™\n",
            "\n",
            "welsh_english_male. 100%[===================>] 722.55M  19.0MB/s    in 41s     \n",
            "\n",
            "2020-10-31 14:37:15 (17.8 MB/s) - â€˜welsh_english_male.zipâ€™ saved [757645790/757645790]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TDTO9T7v0nJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9af2502-d07d-4334-d795-50c29c9413f8"
      },
      "source": [
        "cd /content/drive/My Drive/gender_detection/female/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gender_detection/female\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifzcOlY0hwJ"
      },
      "source": [
        "for filename in glob.glob(os.path.join(\"/content/drive/My Drive/gender_detection/female/\", '*.zip')):\n",
        "  print(filename)\n",
        "  \n",
        "  l=filename.split(\"/\")\n",
        "  l_1=l[len(l)-1].split(\"_\")\n",
        "  t=l[len(l)-1]\n",
        "  l_2=l_1[len(l_1)-1].split(\".\")\n",
        "  print(l_2[0])\n",
        "  \n",
        "  !unzip $t -d \"/content/drive/My Drive/gender_detection/female_unzipped/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF2HBMs0D9Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd9f816-21d7-4bce-be61-f8d7d2f6dead"
      },
      "source": [
        "min=100000\n",
        "count=0\n",
        "count1=0\n",
        "g=[]\n",
        "for filename in glob.glob(os.path.join(\"/content/drive/My Drive/gender_detection/male_unzipped/\", '*.wav')):\n",
        "  count1=count1+1\n",
        "  #print(filename)\n",
        "  l=filename.split(\"/\")\n",
        "  l_1=l[len(l)-1].split(\"_\")\n",
        "  t=l_1[0]\n",
        "  #print(t)\n",
        "  if t not in g:\n",
        "    g.append(t)\n",
        "\n",
        "  #print(count1)\n",
        "print(g,count1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nom', 'wem', 'mim', 'som', 'irm', 'scm'] 10160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1bat8s-c3D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5dfb1e-07f7-4b22-af02-5e984a397e42"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfBaPA46SnH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96105d1-290d-4602-858f-bf93058470cc"
      },
      "source": [
        "print(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ngm', 'vem', 'pem', 'com', 'clm', 'knm', 'gum', 'tem', 'tag', 'mlm', 'eum', 'cam', 'gam', 'arm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WiSkYSMdAOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fa5f79-749b-429f-9e2b-67834de019be"
      },
      "source": [
        "import soundfile as sf\n",
        "ob = sf.SoundFile(\"/content/drive/My Drive/gender_detection/male_unzipped/clm_00610_00556859411.wav\")\n",
        "print(ob.samplerate)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSZpSIfUYZrm"
      },
      "source": [
        "for i in range(len(g)):\n",
        "  g=['nom', 'wem', 'mim', 'som', 'irm', 'scm']\n",
        "  data_speech=pd.DataFrame(columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "  hop_length = 512\n",
        "  n_mels =128\n",
        "  n_fft = 2048\n",
        "  #count=0\n",
        "  for filename in glob.glob(os.path.join(\"/content/drive/My Drive/gender_detection/male_unzipped/\", '*.wav')):\n",
        "    l=filename.split(\"/\")\n",
        "    l_1=l[len(l)-1].split(\"_\")\n",
        "    t=l_1[0]\n",
        "    if t == g[i]:\n",
        "      y, sr = librosa.load(filename,sr=None)\n",
        "      #print(librosa.load(filename,sr=None))\n",
        "      # trim silent edges\n",
        "      speech, _ = librosa.effects.trim(y)\n",
        "      #speech=speech[:100000]\n",
        "      if speech.shape[0]>100000:\n",
        "        #print(speech.shape[0])\n",
        "        speech=speech[:100000]\n",
        "        #print(speech.shape[0])\n",
        "        S1=librosa.feature.mfcc(y=speech,sr=sr)\n",
        "        #print(S1)\n",
        "        gender=\"male\"\n",
        "        # if gender == \"f\":\n",
        "        #   gender=\"female\"\n",
        "        # if gender == \"m\":\n",
        "        #   gender = \"male\"\n",
        "        temp=[]\n",
        "        temp1=[]\n",
        "        temp2=[]\n",
        "        temp.append(np.array(S1))\n",
        "        temp1.append(gender)\n",
        "        temp2.append(np.array(sr))\n",
        "        #print(temp)\n",
        "        df_temp=pd.DataFrame(SP is very convinclist(zip(temp,temp2,temp1)),columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "        data_speech=data_speech.append(df_temp)\n",
        "        print(data_speech.shape)\n",
        "\n",
        "\n",
        "  data_speech.to_pickle(\"/content/drive/My Drive/gender_speech_male_\"+str(16+i)+\".pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIVOg7XJqJTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c28cb8-7e03-4d59-8678-95a855fdbeda"
      },
      "source": [
        "cd /content/drive/My Drive/gender_detection/spanish"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gender_detection/spanish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF0-uF5xqMpK"
      },
      "source": [
        "mkdir spanish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSYu31WZrWLy"
      },
      "source": [
        "for filename in glob.glob(os.path.join(\"/content/drive/My Drive/gender_detection/aida_tang_1/aidatatang_200zh/corpus/train\", '*.tar.gz')):\n",
        "  print(filename)\n",
        "  \n",
        "  l=filename.split(\"/\")\n",
        "  l_1=l[len(l)-1].split(\"_\")\n",
        "  t=l[len(l)-1]\n",
        "  l_2=l_1[len(l_1)-1].split(\".\")\n",
        "  print(t)\n",
        "  \n",
        "  !tar -xvzf $t -C \"/content/drive/My Drive/gender_detection/aida_tang/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJCzP1JcxOP"
      },
      "source": [
        "!tar -xvzf \"/content/drive/My Drive/gender_detection/tedx_spanish_corpus.tgz\" -C \"/content/drive/My Drive/gender_detection/spanish/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt0LAZbEtHi2"
      },
      "source": [
        "for i in range(len(g)):  \n",
        "  data_speech=pd.DataFrame(columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "  hop_length = 512\n",
        "  n_mels =128\n",
        "  n_fft = 2048\n",
        "  #count=0\n",
        "  for filename in glob.glob(os.path.join(\"/content/drive/My Drive/gender_detection/female_1/\", '*.wav')):\n",
        "    l=filename.split(\"/\")\n",
        "    l_1=l[len(l)-1].split(\"_\")\n",
        "    t=l_1[0]\n",
        "    if t == g[i]:\n",
        "      y, sr = librosa.load(filename,sr=None)\n",
        "      #print(librosa.load(filename,sr=None))\n",
        "      # trim silent edges\n",
        "      speech, _ = librosa.effects.trim(y)\n",
        "      #speech=speech[:100000]\n",
        "      if speech.shape[0]>100000:\n",
        "        #print(speech.shape[0])\n",
        "        speech=speech[:100000]\n",
        "        #print(speech.shape[0])\n",
        "        S1=librosa.feature.mfcc(y=speech,sr=sr)\n",
        "        #print(S1)\n",
        "        gender=\"female\"\n",
        "        # if gender == \"f\":\n",
        "        #   gender=\"female\"\n",
        "        # if gender == \"m\":\n",
        "        #   gender = \"male\"\n",
        "        temp=[]\n",
        "        temp1=[]\n",
        "        temp2=[]\n",
        "        temp.append(np.array(S1))\n",
        "        temp1.append(gender)\n",
        "        temp2.append(np.array(sr))\n",
        "        #print(temp)\n",
        "        df_temp=pd.DataFrame(list(zip(temp,temp2,temp1)),columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "        data_speech=data_speech.append(df_temp)\n",
        "        print(data_speech.shape)\n",
        "\n",
        "\n",
        "  data_speech.to_pickle(\"/content/drive/My Drive/gender_speech_female_\"+str(i+2)+\".pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ_8s9M7zBrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe5c982-0e2a-4322-f583-786bc0fa7869"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzOWpH5K1bMP"
      },
      "source": [
        "df_1=pd.read_pickle(\"/content/drive/My Drive/gender_speech_male_1.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0kpBSGZ1oJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8127cddc-385f-4b54-fbeb-8562c77f521e"
      },
      "source": [
        "df_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1</th>\n",
              "      <th>sr</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-589.0368806205586, -590.7716252810573, -593...</td>\n",
              "      <td>48000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-745.5029158777608, -743.6093036397574, -746...</td>\n",
              "      <td>48000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-559.6305392252254, -553.2311500801395, -546...</td>\n",
              "      <td>48000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-522.9313127521281, -502.93893466367575, -51...</td>\n",
              "      <td>48000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-698.6738918884931, -698.4536850934711, -699...</td>\n",
              "      <td>48000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  S1     sr Gender\n",
              "0  [[-589.0368806205586, -590.7716252810573, -593...  48000   male\n",
              "0  [[-745.5029158777608, -743.6093036397574, -746...  48000   male\n",
              "0  [[-559.6305392252254, -553.2311500801395, -546...  48000   male\n",
              "0  [[-522.9313127521281, -502.93893466367575, -51...  48000   male\n",
              "0  [[-698.6738918884931, -698.4536850934711, -699...  48000   male"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwtOTdYd1-i6"
      },
      "source": [
        "df_male=pd.DataFrame(columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "for i in range(16,22):\n",
        "  df_1=pd.read_pickle(\"/content/drive/My Drive/gender_speech_male_\"+str(i)+\".pkl\")\n",
        "  df_male=df_male.append(df_1)\n",
        "# train_inputs, test_inputs, train_labels, test_labels = train_test_split(df_male[\"S1\"], df_male[\"Gender\"],random_state=2018, test_size=0.1)\n",
        "# Scaler=StandardScaler()\n",
        "# train_inputs=Scaler.fit_transform(train_inputs)\n",
        "# test_inputs=Scaler.transform(test_inputs)\n",
        "# data_male_train = {\"S1\": train_inputs, \n",
        "#         \"Gender\": train_labels} \n",
        "# df_male_train = pd.concat(data_male_train, \n",
        "#                axis = 1) \n",
        "# data_male_test = {\"S1\": test_inputs, \n",
        "#         \"Gender\": test_labels} \n",
        "# df_male_test = pd.concat(data_male_test, \n",
        "#                axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zcd7h8qrAoo"
      },
      "source": [
        "df_female=pd.DataFrame(columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "for i in range(19,24):\n",
        "  df_1=pd.read_pickle(\"/content/drive/My Drive/gender_speech_female_\"+str(i)+\".pkl\")\n",
        "  df_female=df_female.append(df_1)\n",
        "# train_inputs, test_inputs, train_labels, test_labels = train_test_split(df_female[\"S1\"], df_female[\"Gender\"],random_state=2018, test_size=0.1)\n",
        "# Scaler=StandardScaler()\n",
        "# train_inputs=Scaler.fit_transform(train_inputs)\n",
        "# test_inputs=Scaler.transform(test_inputs)\n",
        "# data_female_train = {\"S1\": train_inputs, \n",
        "#         \"Gender\": train_labels} \n",
        "# df_female_train = pd.concat(data_female_train, \n",
        "#                axis = 1) \n",
        "# data_female_test = {\"S1\": test_inputs, \n",
        "#         \"Gender\": test_labels} \n",
        "# df_female_test = pd.concat(data_female_test, \n",
        "#                axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR-8HiFts3xP"
      },
      "source": [
        "df=pd.DataFrame(columns=[\"S1\",\"sr\",\"Gender\"])\n",
        "df=df.append(df_male)\n",
        "df=df.append(df_female)\n",
        "df=df.sample(frac=1)\n",
        "\n",
        "# df_test=pd.DataFrame(columns=[\"S1\",\"Gender\"])\n",
        "# df_test=df_test.append(df_male_test)\n",
        "# df_test=df_test.append(df_female_test)\n",
        "# df_test=df_test.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N_4qj_dO9Ey"
      },
      "source": [
        "df.to_pickle(\"/content/drive/My Drive/gender_detection/gender_speech_english.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RryWLTf3PPo4"
      },
      "source": [
        "df_0=pd.read_pickle(\"/content/drive/My Drive/gender_detection/gender_speech.pkl\")\n",
        "df_1=pd.read_pickle(\"/content/drive/My Drive/gender_detection/gender_speech_english.pkl\")\n",
        "df=df_0.append(df_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-NKTwOFA8xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cc920b-1a3c-4eb6-92bc-48bc898c996b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95783, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AJxF2W8A-iD"
      },
      "source": [
        "test=df[\"Gender\"]\n",
        "train=df.drop(\"Gender\",axis=1)\n",
        "train=train.drop(\"sr\",axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L2BoBDmBc2q"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(train,test,random_state=1,test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVQE8tmABvcj"
      },
      "source": [
        "Y_1={\"Gender\":Y_train}\n",
        "Y_1=pd.DataFrame(Y_1)\n",
        "Y_2={\"Gender\":Y_test}\n",
        "Y_2=pd.DataFrame(Y_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cFflfp-OpMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8c5ac1-62e6-47aa-aec7-abcf503ecc1c"
      },
      "source": [
        "X_train[\"Gender\"]=Y_1[\"Gender\"]\n",
        "X_test[\"Gender\"]=Y_2[\"Gender\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu2KqFJoBkSd"
      },
      "source": [
        "# Scaler=StandardScaler()\n",
        "# for i in range(X_train.shape[0]):\n",
        "#   X_train[\"S1\"].values[i]=Scaler.fit_transform(X_train[\"S1\"].values[i])\n",
        "# for i in range(X_test.shape[0]):\n",
        "#   X_test[\"S1\"].values[i]=Scaler.transform(X_test[\"S1\"].values[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OihQcYKlV0Qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fea3a9-5da8-4029-cb6b-5f9ae351d05d"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9PhnLHrJDp"
      },
      "source": [
        "def custom_dataloader(df,N):\n",
        "  size=df.shape[0]\n",
        "  final2=[]\n",
        "  for j in range(int(size/N)):\n",
        "    #print(j)\n",
        "    data_points=[]\n",
        "    data_labels=[]\n",
        "    final=[]\n",
        "    final1=[]\n",
        "    for i in range(N):\n",
        "      s=randint(0,df.shape[0]-1)\n",
        "      input=df[\"S1\"].values[s]\n",
        "      labels=df[\"Gender\"].values[s]\n",
        "      if labels == \"female\":\n",
        "        labels=0\n",
        "      else:\n",
        "        labels=1\n",
        "\n",
        "      data_labels.append((input,labels))\n",
        "    data_labels=tuple(data_labels)\n",
        "    \n",
        "    for points in data_labels:\n",
        "      data,labels=points\n",
        "      \n",
        "      final.append(labels)\n",
        "      data_points.append(data)\n",
        "    \n",
        "    final=torch.tensor(final)\n",
        "    \n",
        "    data_points=torch.tensor(data_points)\n",
        "    data_points=data_points.float()\n",
        "    data_points=data_points.reshape(N,data_points.shape[2],data_points.shape[1])\n",
        "    final1.append(data_points)\n",
        "    final1.append(final)\n",
        "    final2.append(final1)\n",
        "  \n",
        "  return final2\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_NLUz-jrvqA"
      },
      "source": [
        "def init_weights(m):\n",
        "  \n",
        "  if type(m) == nn.Linear or type(m)== nn.Conv2d:\n",
        "    nn.init.xavier_normal_(m.weight)\n",
        "    #print(m.weight)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZuLN79kr5IV"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(LeNet, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv1d(196, 32, 3),         \n",
        "            nn.ReLU(),\n",
        "            #nn.MaxPool2d(2, stride=2),  \n",
        "            nn.Conv1d(32, 48, 3),        \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),   \n",
        "            nn.Conv1d(24, 120, 3),         \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2)  \n",
        "        )\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(180,64),        \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,2),\n",
        "            nn.ReLU()            \n",
        "        )\n",
        "        self.size=180\n",
        "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "        self.eps=1e-9\n",
        "\n",
        "       \n",
        "        #nn.init.xavier_normal_(self.cnn_model.weight)\n",
        "        #nn.init.xavier_normal_(self.fc_model.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.cnn_model(x)\n",
        "        #print(\"before fcc \",x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.alpha * (x - x.mean(dim=-1, keepdim=True))/(x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "        x = self.fc_model(x)\n",
        "        #print(\"after fcc \",x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfPSZZ65r84D"
      },
      "source": [
        "import torch.optim as optim\n",
        "net = LeNet().to(device)\n",
        "net.apply(init_weights)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbALygmisKT3"
      },
      "source": [
        "# Keep only a single checkpoint, the best over test accuracy.\n",
        "def save_checkpoint(state, is_best, filename='/content/drive/My Drive/gender_detection/checkpoint.pth.tar'):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "    if is_best:\n",
        "        print (\"=> Saving a new best\")\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Training Loss did not improve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDaLQGVbsLJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03224917-ca33-4bf4-84d7-553032e68600"
      },
      "source": [
        "resume_weights = '/content/drive/My Drive/gender_detection/checkpoint.pth.tar'\n",
        "import os.path\n",
        "# If exists a best model, load its weights!\n",
        "if os.path.isfile(resume_weights):\n",
        "    #print(\"=> loading checkpoint '{}' ...\".format(resume_weights))\n",
        "    if device:\n",
        "        checkpoint = torch.load(resume_weights)\n",
        "    else:\n",
        "        # Load GPU model on CPU\n",
        "        checkpoint = torch.load(resume_weights,\n",
        "                                map_location=lambda storage,\n",
        "                                loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    net.load_state_dict(checkpoint['state_dict'])\n",
        "    print(\"=> loaded checkpoint '{}' (trained for {} epochs)\",checkpoint['epoch'],best_accuracy,start_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loaded checkpoint '{}' (trained for {} epochs) 89 tensor([98.4060]) 89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6QUUzcpxKeC"
      },
      "source": [
        "start_epoch=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVECm3-_sB0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b594fbd1810b4b159b457704732b4a93",
            "2693dc386d014fb08cc41f5a5676fa7d",
            "54eb6dc89e9e4412857ac1a1f3ad92cb",
            "79d01993f70046a0a18019632aa9a3b9",
            "6aa2f31ee9734303be828c562b279a99",
            "d1e335d31f4640f79dbd6ea5c32788cc",
            "64a65d46d01349ba8997915ee76f8de5",
            "3930ec55c0464582ac367faf1d76c693"
          ]
        },
        "outputId": "b234c968-4f77-4d7c-d75f-f58b72a22231"
      },
      "source": [
        "import time\n",
        "max_epochs = 100\n",
        "best_accuracy=torch.FloatTensor([98.1942])\n",
        "loss_arr=[]\n",
        "loss_epoch_arr=[]\n",
        "for epoch in tqdm_notebook(range(max_epochs),total=(max_epochs),unit=\"epoch\"):\n",
        "  net.train()\n",
        "  train_dataloader = custom_dataloader(X_train,128)\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    t0=time.time()\n",
        "    inputs, labels = data\n",
        "    #print(inputs.shape)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    #print(inputs)\n",
        "    #inputs=inputs\n",
        "    opt.zero_grad()\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    #print(outputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    loss.backward(retain_graph=True)\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "    loss_arr.append(loss.item())\n",
        "    #loss.backward()\n",
        "    opt.step()\n",
        "    t1=time.time()\n",
        "    #print(\"time\",t1-t0)\n",
        "  loss_epoch_arr.append(loss.item())\n",
        "  print('Epoch: %d/%d' % (epoch, max_epochs))\n",
        "  print(\"Training Loss: \",loss.item())\n",
        "  test_dataloader=custom_dataloader(X_test,64)\n",
        "  acc=evaluation(test_dataloader)\n",
        "  print(\"evaluation: \",acc)\n",
        "  acc=torch.FloatTensor([acc])\n",
        "  is_best=bool(acc.numpy() > best_accuracy.numpy())\n",
        "  print(is_best)\n",
        "  best_accuracy=torch.FloatTensor(max(acc.numpy(),best_accuracy.numpy()))\n",
        "  save_checkpoint({\n",
        "      'epoch':start_epoch+epoch+1,\n",
        "      'state_dict':net.state_dict(),\n",
        "      'best_accuracy':best_accuracy\n",
        "  },is_best)\n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b594fbd1810b4b159b457704732b4a93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/100\n",
            "Training Loss:  0.04115878790616989\n",
            "evaluation:  97.61954697986577\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 1/100\n",
            "Training Loss:  0.01865069940686226\n",
            "evaluation:  98.03901006711409\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 2/100\n",
            "Training Loss:  0.030731962993741035\n",
            "evaluation:  98.35360738255034\n",
            "True\n",
            "=> Saving a new best\n",
            "Epoch: 3/100\n",
            "Training Loss:  0.028396548703312874\n",
            "evaluation:  97.93414429530202\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 4/100\n",
            "Training Loss:  0.043771542608737946\n",
            "evaluation:  97.89219798657719\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 5/100\n",
            "Training Loss:  0.05485107749700546\n",
            "evaluation:  98.32214765100672\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 6/100\n",
            "Training Loss:  0.011260205879807472\n",
            "evaluation:  97.80830536912751\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 7/100\n",
            "Training Loss:  0.052923187613487244\n",
            "evaluation:  97.94463087248322\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 8/100\n",
            "Training Loss:  0.01767546497285366\n",
            "evaluation:  98.40604026845638\n",
            "True\n",
            "=> Saving a new best\n",
            "Epoch: 9/100\n",
            "Training Loss:  0.03550727292895317\n",
            "evaluation:  98.15436241610739\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 10/100\n",
            "Training Loss:  0.02691829949617386\n",
            "evaluation:  97.96560402684564\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 11/100\n",
            "Training Loss:  0.04153670743107796\n",
            "evaluation:  97.85025167785236\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 12/100\n",
            "Training Loss:  0.04619191586971283\n",
            "evaluation:  97.76635906040268\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 13/100\n",
            "Training Loss:  0.022272586822509766\n",
            "evaluation:  97.71392617449665\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 14/100\n",
            "Training Loss:  0.035643063485622406\n",
            "evaluation:  97.92365771812081\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 15/100\n",
            "Training Loss:  0.02714422717690468\n",
            "evaluation:  97.83976510067114\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 16/100\n",
            "Training Loss:  0.030646996572613716\n",
            "evaluation:  98.3116610738255\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 17/100\n",
            "Training Loss:  0.07301652431488037\n",
            "evaluation:  97.77684563758389\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 18/100\n",
            "Training Loss:  0.009354094043374062\n",
            "evaluation:  97.86073825503355\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 19/100\n",
            "Training Loss:  0.02293398790061474\n",
            "evaluation:  97.93414429530202\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 20/100\n",
            "Training Loss:  0.01022577565163374\n",
            "evaluation:  98.03901006711409\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 21/100\n",
            "Training Loss:  0.039486829191446304\n",
            "evaluation:  97.29446308724832\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 22/100\n",
            "Training Loss:  0.0025280441623181105\n",
            "evaluation:  97.89219798657719\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 23/100\n",
            "Training Loss:  0.007347739301621914\n",
            "evaluation:  97.63003355704699\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 24/100\n",
            "Training Loss:  0.0011365065583959222\n",
            "evaluation:  97.73489932885906\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 25/100\n",
            "Training Loss:  0.00408591004088521\n",
            "evaluation:  98.11241610738254\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 26/100\n",
            "Training Loss:  0.002958567813038826\n",
            "evaluation:  97.44127516778524\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 27/100\n",
            "Training Loss:  0.008346890099346638\n",
            "evaluation:  97.70343959731544\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 28/100\n",
            "Training Loss:  0.012259372510015965\n",
            "evaluation:  97.70343959731544\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 29/100\n",
            "Training Loss:  0.0025314725935459137\n",
            "evaluation:  97.72441275167785\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 30/100\n",
            "Training Loss:  0.028006279841065407\n",
            "evaluation:  97.87122483221476\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 31/100\n",
            "Training Loss:  0.0013845018111169338\n",
            "evaluation:  97.83976510067114\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 32/100\n",
            "Training Loss:  0.03775186091661453\n",
            "evaluation:  97.16862416107382\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 33/100\n",
            "Training Loss:  0.00042064095032401383\n",
            "evaluation:  97.93414429530202\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 34/100\n",
            "Training Loss:  0.0016895316075533628\n",
            "evaluation:  98.09144295302013\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 35/100\n",
            "Training Loss:  0.009794756770133972\n",
            "evaluation:  98.10192953020135\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 36/100\n",
            "Training Loss:  0.033350102603435516\n",
            "evaluation:  97.76635906040268\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 37/100\n",
            "Training Loss:  0.009132985956966877\n",
            "evaluation:  97.77684563758389\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 38/100\n",
            "Training Loss:  0.08804985135793686\n",
            "evaluation:  97.33640939597315\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 39/100\n",
            "Training Loss:  0.013377836905419827\n",
            "evaluation:  97.9131711409396\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 40/100\n",
            "Training Loss:  0.004528007935732603\n",
            "evaluation:  97.63003355704699\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 41/100\n",
            "Training Loss:  0.004220650531351566\n",
            "evaluation:  97.37835570469798\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 42/100\n",
            "Training Loss:  0.0019030430121347308\n",
            "evaluation:  97.44127516778524\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 43/100\n",
            "Training Loss:  0.0013013890711590648\n",
            "evaluation:  97.72441275167785\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 44/100\n",
            "Training Loss:  0.0027958243153989315\n",
            "evaluation:  97.45176174496645\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 45/100\n",
            "Training Loss:  0.00072370411362499\n",
            "evaluation:  97.82927852348993\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 46/100\n",
            "Training Loss:  0.044001027941703796\n",
            "evaluation:  97.72441275167785\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 47/100\n",
            "Training Loss:  0.008092723786830902\n",
            "evaluation:  97.93414429530202\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 48/100\n",
            "Training Loss:  0.005401394795626402\n",
            "evaluation:  97.72441275167785\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 49/100\n",
            "Training Loss:  0.0029189542401582003\n",
            "evaluation:  97.57760067114094\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 50/100\n",
            "Training Loss:  0.0036255379673093557\n",
            "evaluation:  97.56711409395973\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 51/100\n",
            "Training Loss:  0.00030064600287005305\n",
            "evaluation:  97.46224832214764\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 52/100\n",
            "Training Loss:  9.701929229777306e-05\n",
            "evaluation:  97.60906040268456\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 53/100\n",
            "Training Loss:  0.0007794907432980835\n",
            "evaluation:  97.79781879194631\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 54/100\n",
            "Training Loss:  0.005155364982783794\n",
            "evaluation:  97.27348993288591\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 55/100\n",
            "Training Loss:  0.07114626467227936\n",
            "evaluation:  97.64052013422818\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 56/100\n",
            "Training Loss:  0.0020909118466079235\n",
            "evaluation:  97.61954697986577\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 57/100\n",
            "Training Loss:  0.029252666980028152\n",
            "evaluation:  97.03229865771812\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 58/100\n",
            "Training Loss:  0.018095942214131355\n",
            "evaluation:  97.50419463087249\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 59/100\n",
            "Training Loss:  0.005382913630455732\n",
            "evaluation:  97.73489932885906\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 60/100\n",
            "Training Loss:  0.0020732777193188667\n",
            "evaluation:  97.76635906040268\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 61/100\n",
            "Training Loss:  0.00048147415509447455\n",
            "evaluation:  97.47273489932886\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 62/100\n",
            "Training Loss:  0.009378631599247456\n",
            "evaluation:  97.86073825503355\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 63/100\n",
            "Training Loss:  0.00018470520444680005\n",
            "evaluation:  97.94463087248322\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 64/100\n",
            "Training Loss:  0.00017292131087742746\n",
            "evaluation:  97.67197986577182\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 65/100\n",
            "Training Loss:  0.0020757887978106737\n",
            "evaluation:  97.34689597315436\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 66/100\n",
            "Training Loss:  0.03301423415541649\n",
            "evaluation:  97.35738255033557\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 67/100\n",
            "Training Loss:  0.0003412534133531153\n",
            "evaluation:  97.50419463087249\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 68/100\n",
            "Training Loss:  0.00012935235281474888\n",
            "evaluation:  97.90268456375838\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 69/100\n",
            "Training Loss:  0.02013915590941906\n",
            "evaluation:  97.77684563758389\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 70/100\n",
            "Training Loss:  0.016018986701965332\n",
            "evaluation:  97.80830536912751\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 71/100\n",
            "Training Loss:  0.0006401129066944122\n",
            "evaluation:  97.68246644295301\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 72/100\n",
            "Training Loss:  0.015035743825137615\n",
            "evaluation:  97.63003355704699\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 73/100\n",
            "Training Loss:  0.001971314661204815\n",
            "evaluation:  97.76635906040268\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 74/100\n",
            "Training Loss:  0.0004895205493085086\n",
            "evaluation:  97.29446308724832\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 75/100\n",
            "Training Loss:  0.015743203461170197\n",
            "evaluation:  97.81879194630872\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 76/100\n",
            "Training Loss:  0.0011440266389399767\n",
            "evaluation:  97.69295302013423\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 77/100\n",
            "Training Loss:  0.002267648698762059\n",
            "evaluation:  97.6510067114094\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 78/100\n",
            "Training Loss:  0.0010390477254986763\n",
            "evaluation:  98.12290268456375\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 79/100\n",
            "Training Loss:  0.004208849743008614\n",
            "evaluation:  97.75587248322148\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 80/100\n",
            "Training Loss:  4.299478678149171e-05\n",
            "evaluation:  97.7873322147651\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 81/100\n",
            "Training Loss:  0.0018184053478762507\n",
            "evaluation:  97.5251677852349\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 82/100\n",
            "Training Loss:  8.609679207438603e-05\n",
            "evaluation:  97.83976510067114\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 83/100\n",
            "Training Loss:  0.00014702773478347808\n",
            "evaluation:  97.95511744966443\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 84/100\n",
            "Training Loss:  0.0011209514923393726\n",
            "evaluation:  97.61954697986577\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 85/100\n",
            "Training Loss:  0.0014960881089791656\n",
            "evaluation:  97.64052013422818\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 86/100\n",
            "Training Loss:  0.002225304488092661\n",
            "evaluation:  97.97609060402685\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 87/100\n",
            "Training Loss:  0.00022111674479674548\n",
            "evaluation:  98.01803691275168\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 88/100\n",
            "Training Loss:  0.004597807303071022\n",
            "evaluation:  97.89219798657719\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 89/100\n",
            "Training Loss:  0.0012697301572188735\n",
            "evaluation:  97.27348993288591\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 90/100\n",
            "Training Loss:  2.2309293854050338e-05\n",
            "evaluation:  97.54614093959732\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 91/100\n",
            "Training Loss:  1.2169284673291259e-05\n",
            "evaluation:  97.76635906040268\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 92/100\n",
            "Training Loss:  0.005212472751736641\n",
            "evaluation:  97.37835570469798\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 93/100\n",
            "Training Loss:  0.00029116342193447053\n",
            "evaluation:  97.70343959731544\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 94/100\n",
            "Training Loss:  0.00015325193817261606\n",
            "evaluation:  97.44127516778524\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 95/100\n",
            "Training Loss:  0.028530482202768326\n",
            "evaluation:  97.40981543624162\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 96/100\n",
            "Training Loss:  0.0013042106293141842\n",
            "evaluation:  97.38884228187919\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 97/100\n",
            "Training Loss:  0.0015463267918676138\n",
            "evaluation:  98.07046979865771\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 98/100\n",
            "Training Loss:  0.10962477326393127\n",
            "evaluation:  96.99035234899328\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "Epoch: 99/100\n",
            "Training Loss:  7.72729890741175e-06\n",
            "evaluation:  97.83976510067114\n",
            "False\n",
            "=> Training Loss did not improve\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsV-UenExWlF"
      },
      "source": [
        "def evaluation(dataloader):\n",
        "    net.eval()\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        #print(outputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        #print(pred,labels)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    #print(correct,total)\n",
        "    #return 100 * correct / total\n",
        "    return pred,labels,100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDG_KuzxACEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b34970-a902-416f-a2c9-b5136c4f0132"
      },
      "source": [
        "a=evaluation(custom_dataloader(X_test,X_test.shape[0]))\n",
        "label=a[1]\n",
        "pred=a[0]\n",
        "label=label.detach()\n",
        "pred=pred.detach()\n",
        "label=label.cpu()\n",
        "pred=pred.cpu()\n",
        "label=label.numpy()\n",
        "pred=pred.numpy()\n",
        "print(label,pred,a[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 1 0] [1 0 1 ... 0 1 0] 98.1835264641403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUUNXBjTAxfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c636f517-61d8-4d51-971d-7da46cfab592"
      },
      "source": [
        "B=confusion(pred,label)\n",
        "print(\"confusion_matrix\")\n",
        "print(B)\n",
        "\n",
        "precision=B[1,1]/(B[1,1]+B[0,1])\n",
        "print(\"precision\",precision)\n",
        "recall=B[1,1]/(B[1,1]+B[1,0])\n",
        "print(\"recall\",recall)\n",
        "f1=2*precision*recall/(precision+recall)\n",
        "print(\"f1\",f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9579 9579\n",
            "confusion_matrix\n",
            "[[4830.  109.]\n",
            " [  65. 4575.]]\n",
            "precision 0.976729291204099\n",
            "recall 0.9859913793103449\n",
            "f1 0.9813384813384813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzMlX-DHB0Rq"
      },
      "source": [
        "for i in range(len(evaluation(custom_dataloader(X_test,X_test.shape[0]))[0])):\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6XPb-lx_9nw"
      },
      "source": [
        "def confusion(y_pred,y):\n",
        "  true_positive=0\n",
        "  true_negative=0\n",
        "  false_positive=0\n",
        "  false_negative=0\n",
        "  print(len(y),len(y_pred))\n",
        "  for i in range(len(y)):\n",
        "    if y[i]==y_pred[i] and y[i]==1:\n",
        "      true_positive+=1\n",
        "    if y[i]==1 and y_pred[i]==0:\n",
        "      false_negative+=1\n",
        "    if y[i]==0 and y_pred[i]==1:\n",
        "      false_positive+=1\n",
        "    if y[i]==y_pred[i] and y[i]==0:\n",
        "      true_negative+=1\n",
        "\n",
        "  A=np.random.randn(2,2)\n",
        "  A[1,1]=true_positive\n",
        "  A[0,0]=true_negative\n",
        "  A[1,0]=false_positive\n",
        "  A[0,1]=false_negative\n",
        "  return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN9k1mDrthWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf11e7ed-6f35-4de8-adf3-e9460c802b81"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiUgI164XUET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6d69f617-00c7-4b11-9649-13336217d18b"
      },
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "audio, sr = get_audio()\n",
        "import scipy\n",
        "scipy.io.wavfile.write('recording.wav', sr, audio)\n",
        "y, sr = librosa.load(\"/content/recording.wav\",sr=None)\n",
        "speech, _ = librosa.effects.trim(y)\n",
        "\n",
        "speech=speech[:100000]\n",
        "S1=librosa.feature.mfcc(y=speech,sr=sr)\n",
        "S1=torch.tensor(S1)\n",
        "S1=S1.float()\n",
        "S1=S1.reshape(1,S1.shape[1],S1.shape[0])\n",
        "S1=S1.to(device)\n",
        "out=net(S1)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 1.7261]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}